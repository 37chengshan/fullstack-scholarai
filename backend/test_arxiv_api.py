"""
Test arXiv API Implementation
æµ‹è¯•arXiv APIé›†æˆåŠŸèƒ½
"""

import sys
import os

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.arxiv_client import ArxivClient, get_arxiv_client
import asyncio


async def test_basic_search():
    """Test 1: åŸºç¡€å…³é”®è¯æœç´¢"""
    print("\n=== Test 1: åŸºç¡€å…³é”®è¯æœç´¢ ===")

    client = get_arxiv_client()
    result = await client.search_papers(
        query="deep learning",
        page=1,
        page_size=5
    )

    if result['success']:
        data = result['data']
        print(f"âœ… æœç´¢æˆåŠŸ!")
        print(f"   - æ€»è®ºæ–‡æ•°: {data['total']}")
        print(f"   - å½“å‰é¡µ: {data['page']}/{data['total_pages']}")
        print(f"   - è¿”å›è®ºæ–‡æ•°: {len(data['papers'])}")

        if data['papers']:
            paper = data['papers'][0]
            print(f"   - ç¬¬ä¸€ç¯‡è®ºæ–‡:")
            print(f"     * ID: {paper['paper_id']}")
            print(f"     * æ ‡é¢˜: {paper['title']}")
            print(f"     * ä½œè€…: {', '.join(paper['authors'][:3])}{'...' if len(paper['authors']) > 3 else ''}")
            print(f"     * åˆ†ç±»: {paper['primary_category']}")
            return True
        else:
            print("âŒ æ²¡æœ‰è¿”å›è®ºæ–‡")
            return False
    else:
        print(f"âŒ æœç´¢å¤±è´¥: {result.get('error')}")
        return False


async def test_field_filter():
    """Test 2: é¢†åŸŸè¿‡æ»¤æœç´¢"""
    print("\n=== Test 2: é¢†åŸŸè¿‡æ»¤æœç´¢ (cs.AI) ===")

    client = get_arxiv_client()
    result = await client.search_papers(
        query="transformers",
        field="cs.AI",  # AIé¢†åŸŸ
        page=1,
        page_size=5
    )

    if result['success']:
        data = result['data']
        print(f"âœ… é¢†åŸŸæœç´¢æˆåŠŸ!")
        print(f"   - æ€»è®ºæ–‡æ•°: {data['total']}")

        # æ£€æŸ¥æ‰€æœ‰è®ºæ–‡æ˜¯å¦å±äºcs.AI
        all_ai = True
        for paper in data['papers']:
            if 'cs.AI' not in paper['categories']:
                all_ai = False
                print(f"   âš ï¸  è®ºæ–‡ {paper['paper_id']} ä¸å±äºcs.AI")
                break

        if all_ai and data['papers']:
            print(f"   âœ… æ‰€æœ‰è®ºæ–‡éƒ½å±äºcs.AIé¢†åŸŸ")
            return True
        else:
            print(f"   âŒ é¢†åŸŸè¿‡æ»¤å¯èƒ½æœ‰é—®é¢˜")
            return False
    else:
        print(f"âŒ é¢†åŸŸæœç´¢å¤±è´¥: {result.get('error')}")
        return False


async def test_year_filter():
    """Test 3: å¹´ä»½èŒƒå›´è¿‡æ»¤"""
    print("\n=== Test 3: å¹´ä»½èŒƒå›´è¿‡æ»¤ (2023-2024) ===")

    client = get_arxiv_client()
    result = await client.search_papers(
        query="neural networks",
        year_min=2023,
        year_max=2024,
        page=1,
        page_size=5
    )

    if result['success']:
        data = result['data']
        print(f"âœ… å¹´ä»½è¿‡æ»¤æœç´¢æˆåŠŸ!")
        print(f"   - æ€»è®ºæ–‡æ•°: {data['total']}")

        # æ£€æŸ¥æ‰€æœ‰è®ºæ–‡æ˜¯å¦åœ¨æŒ‡å®šå¹´ä»½èŒƒå›´å†…
        all_in_range = True
        for paper in data['papers']:
            year = paper['published_year']
            if year and (year < 2023 or year > 2024):
                all_in_range = False
                print(f"   âš ï¸  è®ºæ–‡ {paper['paper_id']} å¹´ä»½ {year} ä¸åœ¨èŒƒå›´å†…")
                break

        if all_in_range and data['papers']:
            print(f"   âœ… æ‰€æœ‰è®ºæ–‡éƒ½åœ¨2023-2024èŒƒå›´å†…")
            return True
        else:
            print(f"   âŒ å¹´ä»½è¿‡æ»¤å¯èƒ½æœ‰é—®é¢˜")
            return False
    else:
        print(f"âŒ å¹´ä»½è¿‡æ»¤æœç´¢å¤±è´¥: {result.get('error')}")
        return False


async def test_pagination():
    """Test 4: åˆ†é¡µåŠŸèƒ½"""
    print("\n=== Test 4: åˆ†é¡µåŠŸèƒ½ ===")

    client = get_arxiv_client()

    # ç¬¬ä¸€é¡µ
    result1 = await client.search_papers(
        query="machine learning",
        page=1,
        page_size=3
    )

    # ç¬¬äºŒé¡µ
    result2 = await client.search_papers(
        query="machine learning",
        page=2,
        page_size=3
    )

    if result1['success'] and result2['success']:
        papers_page1 = [p['paper_id'] for p in result1['data']['papers']]
        papers_page2 = [p['paper_id'] for p in result2['data']['papers']]

        # æ£€æŸ¥ä¸¤é¡µè®ºæ–‡ä¸é‡å¤
        overlap = set(papers_page1) & set(papers_page2)

        print(f"âœ… åˆ†é¡µæµ‹è¯•é€šè¿‡!")
        print(f"   - ç¬¬1é¡µè®ºæ–‡æ•°: {len(papers_page1)}")
        print(f"   - ç¬¬2é¡µè®ºæ–‡æ•°: {len(papers_page2)}")
        print(f"   - é‡å¤è®ºæ–‡æ•°: {len(overlap)}")

        if len(overlap) == 0:
            print(f"   âœ… ä¸¤é¡µè®ºæ–‡ä¸é‡å¤ï¼Œåˆ†é¡µæ­£ç¡®")
            return True
        else:
            print(f"   âš ï¸  å­˜åœ¨é‡å¤è®ºæ–‡: {overlap}")
            return True  # arXivå¯èƒ½è¿”å›ç›¸åŒè®ºæ–‡çš„ä¸åŒç‰ˆæœ¬
    else:
        print(f"âŒ åˆ†é¡µæµ‹è¯•å¤±è´¥")
        return False


async def test_get_paper_details():
    """Test 5: è·å–è®ºæ–‡è¯¦æƒ…"""
    print("\n=== Test 5: è·å–è®ºæ–‡è¯¦æƒ… ===")

    client = get_arxiv_client()

    # å…ˆæœç´¢ä¸€ç¯‡è®ºæ–‡
    search_result = await client.search_papers(
        query="attention is all you need",
        page_size=1
    )

    if search_result['success'] and search_result['data']['papers']:
        paper_id = search_result['data']['papers'][0]['paper_id']

        # è·å–è¯¦æƒ…
        detail_result = await client.get_paper_details(paper_id)

        if detail_result['success']:
            paper = detail_result['data']
            print(f"âœ… è·å–è®ºæ–‡è¯¦æƒ…æˆåŠŸ!")
            print(f"   - è®ºæ–‡ID: {paper['paper_id']}")
            print(f"   - æ ‡é¢˜: {paper['title']}")
            print(f"   - ä½œè€…æ•°: {len(paper['authors'])}")
            print(f"   - æ‘˜è¦é•¿åº¦: {len(paper['summary'])} å­—ç¬¦")
            print(f"   - åˆ†ç±»æ•°: {len(paper['categories'])}")
            print(f"   - PDFé“¾æ¥: {'âœ… æœ‰' if paper['pdf_url'] else 'âŒ æ— '}")
            return True
        else:
            print(f"âŒ è·å–è®ºæ–‡è¯¦æƒ…å¤±è´¥: {detail_result.get('error')}")
            return False
    else:
        print(f"âŒ æœç´¢è®ºæ–‡å¤±è´¥")
        return False


async def test_get_pdf_url():
    """Test 6: è·å–PDF URL"""
    print("\n=== Test 6: è·å–PDF URL ===")

    client = get_arxiv_client()
    result = await client.get_paper_pdf_url("2301.00001")

    if result['success']:
        pdf_url = result['data']['pdf_url']
        print(f"âœ… è·å–PDF URLæˆåŠŸ!")
        print(f"   - PDF URL: {pdf_url}")
        print(f"   - URLæ ¼å¼æ­£ç¡®: {'âœ… æ˜¯' if pdf_url.startswith('https://arxiv.org/pdf/') else 'âŒ å¦'}")
        return True
    else:
        print(f"âŒ è·å–PDF URLå¤±è´¥: {result.get('error')}")
        return False


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("arXiv API Integration Tests")
    print("="*60)

    tests = [
        ("åŸºç¡€å…³é”®è¯æœç´¢", test_basic_search),
        ("é¢†åŸŸè¿‡æ»¤æœç´¢", test_field_filter),
        ("å¹´ä»½èŒƒå›´è¿‡æ»¤", test_year_filter),
        ("åˆ†é¡µåŠŸèƒ½", test_pagination),
        ("è·å–è®ºæ–‡è¯¦æƒ…", test_get_paper_details),
        ("è·å–PDF URL", test_get_pdf_url)
    ]

    passed = 0
    failed = 0

    for test_name, test_func in tests:
        try:
            if await test_func():
                passed += 1
            else:
                failed += 1
        except Exception as e:
            print(f"âŒ æµ‹è¯• '{test_name}' å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            failed += 1

    # è¾“å‡ºæµ‹è¯•æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    print(f"âœ… é€šè¿‡: {passed}/{len(tests)}")
    print(f"âŒ å¤±è´¥: {failed}/{len(tests)}")

    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
        return 0
    else:
        print(f"\nâš ï¸  {failed}ä¸ªæµ‹è¯•å¤±è´¥")
        return 1


if __name__ == '__main__':
    exit_code = asyncio.run(run_all_tests())
    sys.exit(exit_code)
