"""
æ™ºè°±AIå®¢æˆ·ç«¯æµ‹è¯•è„šæœ¬
æµ‹è¯•ZhipuClientçš„å„é¡¹åŠŸèƒ½
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from services.zhipu_client import ZhipuClient, get_zhipu_client


async def test_connection():
    """æµ‹è¯•1: APIè¿æ¥æµ‹è¯•"""
    print("\n" + "="*60)
    print("æµ‹è¯•1: APIè¿æ¥æµ‹è¯•")
    print("="*60)

    try:
        client = get_zhipu_client()
        result = await client.test_connection()

        if result["success"]:
            print("âœ… APIè¿æ¥æˆåŠŸ")
            print(f"   æ¨¡å‹: {result.get('model')}")
            return True
        else:
            print(f"âŒ APIè¿æ¥å¤±è´¥: {result.get('message')}")
            return False

    except Exception as e:
        print(f"âŒ è¿æ¥æµ‹è¯•å¼‚å¸¸: {e}")
        return False


async def test_chat_completion():
    """æµ‹è¯•2: åŸºç¡€èŠå¤©è¡¥å…¨"""
    print("\n" + "="*60)
    print("æµ‹è¯•2: åŸºç¡€èŠå¤©è¡¥å…¨")
    print("="*60)

    try:
        client = get_zhipu_client()

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": "è¯·ç”¨ä¸€å¥è¯ä»‹ç»æ™ºè°±AIã€‚"}
        ]

        print(f"å‘é€æ¶ˆæ¯: {messages[-1]['content']}")

        result = await client.chat_completion(
            messages=messages,
            model="glm-4-flash",
            max_tokens=100
        )

        if result["success"]:
            content = result["data"]["choices"][0]["message"]["content"]
            print(f"âœ… èŠå¤©è¡¥å…¨æˆåŠŸ")
            print(f"   å›å¤: {content}")
            return True
        else:
            print(f"âŒ èŠå¤©è¡¥å…¨å¤±è´¥: {result.get('error')}")
            return False

    except Exception as e:
        print(f"âŒ èŠå¤©è¡¥å…¨å¼‚å¸¸: {e}")
        return False


async def test_stream_chat():
    """æµ‹è¯•3: æµå¼èŠå¤©è¡¥å…¨"""
    print("\n" + "="*60)
    print("æµ‹è¯•3: æµå¼èŠå¤©è¡¥å…¨")
    print("="*60)

    try:
        client = get_zhipu_client()

        messages = [
            {"role": "user", "content": "è¯·æ•°åˆ°5ï¼Œæ¯ä¸ªæ•°å­—ä¹‹é—´ç”¨ç©ºæ ¼åˆ†éš”ã€‚"}
        ]

        print(f"å‘é€æ¶ˆæ¯: {messages[-1]['content']}")
        print("æµå¼å›å¤: ", end="", flush=True)

        full_response = ""
        async for chunk in client.chat_completion_stream(messages=messages):
            print(chunk, end="", flush=True)
            full_response += chunk

        print(f"\nâœ… æµå¼èŠå¤©æˆåŠŸ")
        print(f"   å®Œæ•´å›å¤: {full_response}")
        return True

    except Exception as e:
        print(f"\nâŒ æµå¼èŠå¤©å¼‚å¸¸: {e}")
        return False


async def test_paper_analysis():
    """æµ‹è¯•4: è®ºæ–‡åˆ†æåœºæ™¯"""
    print("\n" + "="*60)
    print("æµ‹è¯•4: è®ºæ–‡åˆ†æåœºæ™¯")
    print("="*60)

    try:
        client = get_zhipu_client()

        # æ¨¡æ‹Ÿè®ºæ–‡åˆ†æ
        paper_abstract = """
        This paper proposes a novel deep learning architecture for natural language understanding.
        Our approach combines transformer-based models with graph neural networks to capture
        both local and global dependencies in text. Extensive experiments on benchmark
        datasets demonstrate state-of-the-art performance.
        """

        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡åŠ©æ‰‹ã€‚è¯·ç®€æ´åœ°æ€»ç»“è®ºæ–‡è¦ç‚¹ã€‚"
            },
            {
                "role": "user",
                "content": f"è¯·ç”¨ä¸­æ–‡æ€»ç»“ä»¥ä¸‹è®ºæ–‡æ‘˜è¦çš„æ ¸å¿ƒè´¡çŒ®ï¼ˆä¸è¶…è¿‡100å­—ï¼‰ï¼š\n\n{paper_abstract}"
            }
        ]

        print(f"è®ºæ–‡åˆ†æè¯·æ±‚...")

        result = await client.chat_completion(
            messages=messages,
            model="glm-4-flash",
            temperature=0.3,  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šçš„è¾“å‡º
            max_tokens=200
        )

        if result["success"]:
            summary = result["data"]["choices"][0]["message"]["content"]
            print(f"âœ… è®ºæ–‡åˆ†ææˆåŠŸ")
            print(f"   æ‘˜è¦æ€»ç»“: {summary}")
            return True
        else:
            print(f"âŒ è®ºæ–‡åˆ†æå¤±è´¥: {result.get('error')}")
            return False

    except Exception as e:
        print(f"âŒ è®ºæ–‡åˆ†æå¼‚å¸¸: {e}")
        return False


async def test_model_info():
    """æµ‹è¯•5: æ¨¡å‹ä¿¡æ¯"""
    print("\n" + "="*60)
    print("æµ‹è¯•5: æ¨¡å‹ä¿¡æ¯")
    print("="*60)

    try:
        client = get_zhipu_client()

        # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
        models = client.get_available_models()
        print(f"âœ… å¯ç”¨å…è´¹æ¨¡å‹: {', '.join(models)}")

        # æ£€æŸ¥ç‰¹å®šæ¨¡å‹
        test_model = "glm-4-flash"
        is_free = client.is_free_model(test_model)
        print(f"   {test_model} æ˜¯å¦å…è´¹: {is_free}")

        return True

    except Exception as e:
        print(f"âŒ è·å–æ¨¡å‹ä¿¡æ¯å¼‚å¸¸: {e}")
        return False


async def test_error_handling():
    """æµ‹è¯•6: é”™è¯¯å¤„ç†"""
    print("\n" + "="*60)
    print("æµ‹è¯•6: é”™è¯¯å¤„ç†")
    print("="*60)

    try:
        client = get_zhipu_client()

        # æµ‹è¯•æ— æ•ˆæ¨¡å‹
        print("æµ‹è¯•1: æ— æ•ˆæ¨¡å‹åç§°")
        result = await client.chat_completion(
            messages=[{"role": "user", "content": "Hi"}],
            model="invalid-model-name"
        )

        if not result["success"]:
            print(f"âœ… æ­£ç¡®å¤„ç†äº†æ— æ•ˆæ¨¡å‹: {result.get('error', 'Unknown error')[:50]}...")
        else:
            print("âš ï¸  æœªèƒ½æ£€æµ‹åˆ°æ— æ•ˆæ¨¡å‹")

        # æµ‹è¯•ç©ºæ¶ˆæ¯
        print("\næµ‹è¯•2: ç©ºæ¶ˆæ¯åˆ—è¡¨")
        result = await client.chat_completion(messages=[])

        if not result["success"]:
            print(f"âœ… æ­£ç¡®å¤„ç†äº†ç©ºæ¶ˆæ¯: {result.get('error', 'Unknown error')[:50]}...")
        else:
            print("âš ï¸  æœªèƒ½æ£€æµ‹åˆ°ç©ºæ¶ˆæ¯")

        return True

    except Exception as e:
        print(f"âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¼‚å¸¸: {e}")
        return False


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("æ™ºè°±AIå®¢æˆ·ç«¯åŠŸèƒ½æµ‹è¯•")
    print("="*60)

    tests = [
        ("APIè¿æ¥", test_connection),
        ("åŸºç¡€èŠå¤©è¡¥å…¨", test_chat_completion),
        ("æµå¼èŠå¤©", test_stream_chat),
        ("è®ºæ–‡åˆ†æåœºæ™¯", test_paper_analysis),
        ("æ¨¡å‹ä¿¡æ¯", test_model_info),
        ("é”™è¯¯å¤„ç†", test_error_handling)
    ]

    results = []
    for name, test_func in tests:
        try:
            result = await test_func()
            results.append((name, result))
        except Exception as e:
            print(f"\nâŒ æµ‹è¯• '{name}' å‘ç”Ÿæœªæ•è·å¼‚å¸¸: {e}")
            results.append((name, False))

    # æ‰“å°æµ‹è¯•æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)

    passed = sum(1 for _, result in results if result)
    total = len(results)

    for name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status} - {name}")

    print(f"\né€šè¿‡ç‡: {passed}/{total} ({passed*100//total}%)")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(main())
